{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 29601 entries, 0 to 29999\n",
      "Data columns (total 24 columns):\n",
      " #   Column                      Non-Null Count  Dtype\n",
      "---  ------                      --------------  -----\n",
      " 0   LIMIT_BAL                   29601 non-null  int64\n",
      " 1   SEX                         29601 non-null  int64\n",
      " 2   EDUCATION                   29601 non-null  int64\n",
      " 3   MARRIAGE                    29601 non-null  int64\n",
      " 4   AGE                         29601 non-null  int64\n",
      " 5   PAY_0                       29601 non-null  int64\n",
      " 6   PAY_2                       29601 non-null  int64\n",
      " 7   PAY_3                       29601 non-null  int64\n",
      " 8   PAY_4                       29601 non-null  int64\n",
      " 9   PAY_5                       29601 non-null  int64\n",
      " 10  PAY_6                       29601 non-null  int64\n",
      " 11  BILL_AMT1                   29601 non-null  int64\n",
      " 12  BILL_AMT2                   29601 non-null  int64\n",
      " 13  BILL_AMT3                   29601 non-null  int64\n",
      " 14  BILL_AMT4                   29601 non-null  int64\n",
      " 15  BILL_AMT5                   29601 non-null  int64\n",
      " 16  BILL_AMT6                   29601 non-null  int64\n",
      " 17  PAY_AMT1                    29601 non-null  int64\n",
      " 18  PAY_AMT2                    29601 non-null  int64\n",
      " 19  PAY_AMT3                    29601 non-null  int64\n",
      " 20  PAY_AMT4                    29601 non-null  int64\n",
      " 21  PAY_AMT5                    29601 non-null  int64\n",
      " 22  PAY_AMT6                    29601 non-null  int64\n",
      " 23  default payment next month  29601 non-null  int64\n",
      "dtypes: int64(24)\n",
      "memory usage: 5.6 MB\n",
      "---------------------------------------------\n",
      "default payment next month\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.776866\n",
       "1    0.223134\n",
       "Name: default_payment_next_month, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv(\"bank_dataset.csv\")\n",
    "\n",
    "#Deleting ID as useless variable\n",
    "\n",
    "del df['ID']\n",
    "\n",
    "#Dropping education variables 0,5,6 & Marriage status 0\n",
    "#since we don't know what these are per UCI page and these are such a small portion of data less than 3%\n",
    "\n",
    "df_new = df[(df.EDUCATION !=0)&(df.EDUCATION !=5) &\n",
    "            (df.EDUCATION !=6) & (df.MARRIAGE!= 0)\n",
    "           ]\n",
    "#Sex, Education & Marriage are already int values, so need to transform them\n",
    "df_new.info()\n",
    "round(df.describe(),4)\n",
    "\n",
    "#This is concerning that we have an imbalanced dataset\n",
    "#We will need to address this imbalance by uppersampling.\n",
    "print('---------------------------------------------')\n",
    "df_new = df_new.rename(columns={'default payment next month' : 'default_payment_next_month'})\n",
    "print(\"default payment next month\")\n",
    "df_new['default_payment_next_month'].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed is: 293\n",
      "Counter({0: 22996, 1: 6605})\n",
      "OS_breakout Counter({1: 22996, 0: 22996})\n",
      "Since we OS, we now have a more balance dataset.This is clear by the counter counts\n",
      "====Iteration 0  ====\n",
      "Accuracy 0.73\n",
      "sensitivity: 0.73\n",
      "specificity: 0.72\n",
      "====Iteration 1  ====\n",
      "Accuracy 0.72\n",
      "sensitivity: 0.72\n",
      "specificity: 0.72\n",
      "====Iteration 2  ====\n",
      "Accuracy 0.72\n",
      "sensitivity: 0.73\n",
      "specificity: 0.71\n",
      "====Iteration 3  ====\n",
      "Accuracy 0.72\n",
      "sensitivity: 0.73\n",
      "specificity: 0.71\n",
      "====Iteration 4  ====\n",
      "Accuracy 0.72\n",
      "sensitivity: 0.72\n",
      "specificity: 0.72\n",
      "====Iteration 5  ====\n",
      "Accuracy 0.73\n",
      "sensitivity: 0.73\n",
      "specificity: 0.72\n",
      "====Iteration 6  ====\n",
      "Accuracy 0.73\n",
      "sensitivity: 0.73\n",
      "specificity: 0.72\n",
      "====Iteration 7  ====\n",
      "Accuracy 0.72\n",
      "sensitivity: 0.73\n",
      "specificity: 0.71\n",
      "====Iteration 8  ====\n",
      "Accuracy 0.72\n",
      "sensitivity: 0.72\n",
      "specificity: 0.72\n",
      "====Iteration 9  ====\n",
      "Accuracy 0.72\n",
      "sensitivity: 0.72\n",
      "specificity: 0.72\n"
     ]
    }
   ],
   "source": [
    "#Training and testing split.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from collections import Counter\n",
    "import imblearn\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "#Setting Seed\n",
    "#will use this in CV portion\n",
    "random.seed(10)\n",
    "seed = random.randint(1,500)\n",
    "print(\"seed is:\",seed)\n",
    "\n",
    "#Before we do any model building, we need to upper sample \"1\" which is defaults.\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "if 'default_payment_next_month' in df_new:\n",
    "    y = df_new['default_payment_next_month'].values\n",
    "    del df_new['default_payment_next_month']\n",
    "    X = df_new.values\n",
    "\n",
    "#Saving out the column names , so we can make dataframes later on \n",
    "col = ['LIMIT_BAL','SEX','EDUCATION','MARRIAGE','AGE','PAY_0',\n",
    "       'PAY_2','PAY_3','PAY_4','PAY_5','PAY_6','BILL_AMT1','BILL_AMT2',\n",
    "       'BILL_AMT3','BILL_AMT4','BILL_AMT5','BILL_AMT6','PAY_AMT1','PAY_AMT2',\n",
    "       'PAY_AMT3','PAY_AMT4','PAY_AMT5','PAY_AMT6']\n",
    "\n",
    "\n",
    "#Code followed from https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/\n",
    "os = SMOTE(random_state=99)\n",
    "\n",
    "\n",
    "#Our new datasets to use will be X_res,y_res\n",
    "#X_res is the resample dataset that is now more balance\n",
    "#Y_res is the target column that is now more balance.\n",
    "\n",
    "X_res, y_res = os.fit_resample(X, y)\n",
    "\n",
    "#Previous class distribtion\n",
    "counter = Counter(y)\n",
    "print(counter)\n",
    "\n",
    "# summarize the new class distribution\n",
    "counter_res = Counter(y_res)\n",
    "print(\"OS_breakout\",counter_res)\n",
    "print(\"Since we OS, we now have a more balance dataset.This is clear by the counter counts\")\n",
    "\n",
    "\n",
    "\n",
    "#Setting up  the CV, code utlized from 04 Logits & SVM notebook\n",
    "num_cv_iterations = 10\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         random_state = seed,\n",
    "                         test_size  = 0.2)\n",
    "\n",
    "#code utlized from 04 Logits & SVM notebook\n",
    "std_scl = StandardScaler()\n",
    "lr_clf = LogisticRegression(penalty='l2', C=0.05, solver='liblinear') \n",
    "\n",
    "# create the pipline\n",
    "#code utlized from 04 Logits & SVM notebook\n",
    "piped_object = Pipeline([('scale', std_scl),  # do this\n",
    "                         ('logit_model', lr_clf)]) # and then do this\n",
    "\n",
    "\n",
    "#Calc the weights\n",
    "#code utlized from 04 Logits & SVM notebook\n",
    "#We trained our model(including all variables at the moment) on 10 CV with random state set to the seed variable\n",
    "#We are looping through and calcing ACC,Spec and Sensitivty.\n",
    "#This section utliztied code from unit 4 notebook &\n",
    "#https://statinfer.com/204-4-2-calculating-sensitivity-and-specificity-in-python/\n",
    "\n",
    "\n",
    "\n",
    "weights = []\n",
    "for iter_num, (train_indices, test_indices) in enumerate(cv_object.split(X_res,y_res)):\n",
    "    piped_object.fit(X_res[train_indices],y_res[train_indices])  # train object\n",
    "    y_hat = piped_object.predict(X_res[test_indices]) # get test set precitions\n",
    "    weights.append(piped_object.named_steps['logit_model'].coef_[0])\n",
    "    \n",
    "    \n",
    "    cm1 = mt.confusion_matrix(y_res[test_indices],y_hat)\n",
    "    \n",
    "    sensitivity1= cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    \n",
    "    specificity1= cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    \n",
    "    # print the accuracy and confusion matrix \n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"Accuracy\", round(mt.accuracy_score(y_res[test_indices],y_hat),2))\n",
    "   \n",
    "    \n",
    "    print('sensitivity:',round(sensitivity1,2))\n",
    "    print('specificity:',round(specificity1,2))\n",
    "\n",
    "weights = np.array(weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights of General Log model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARRIAGE has weight of -0.5677\n",
      "BILL_AMT1 has weight of -0.5167\n",
      "SEX has weight of -0.3953\n",
      "EDUCATION has weight of -0.3847\n",
      "PAY_AMT1 has weight of -0.2727\n",
      "PAY_AMT2 has weight of -0.2419\n",
      "LIMIT_BAL has weight of -0.1823\n",
      "PAY_AMT3 has weight of -0.0929\n",
      "AGE has weight of -0.0898\n",
      "PAY_AMT4 has weight of -0.0703\n",
      "PAY_AMT5 has weight of -0.062\n",
      "PAY_AMT6 has weight of -0.036\n",
      "BILL_AMT5 has weight of -0.0037\n",
      "PAY_6 has weight of 0.008\n",
      "PAY_4 has weight of 0.0273\n",
      "BILL_AMT4 has weight of 0.0297\n",
      "BILL_AMT6 has weight of 0.0358\n",
      "PAY_3 has weight of 0.071\n",
      "BILL_AMT3 has weight of 0.0815\n",
      "PAY_5 has weight of 0.0912\n",
      "PAY_2 has weight of 0.0987\n",
      "BILL_AMT2 has weight of 0.3155\n",
      "PAY_0 has weight of 0.6212\n"
     ]
    }
   ],
   "source": [
    "#Is this correct? I'm not sure if it's refering to model after scaling \n",
    "\n",
    "zip_vars = zip(lr_clf.coef_.T,df_new.columns) # combine attributes\n",
    "zip_vars = sorted(zip_vars)\n",
    "for coef, name in zip_vars:\n",
    "    print(name, 'has weight of', round(coef[0],4)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eric\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass n_features_to_select=10 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True  True  True  True  True  True  True  True  True  True False\n",
      " False False False False False False False False False False False]\n",
      "[13  1  1  1  1  1  1  1  1  1  1  4  5 11 14 12 10  2  3  7  6  8  9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3',\n",
       "       'PAY_4', 'PAY_5', 'PAY_6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For building our logic model, we used RFE\n",
    "# we utlized code from https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8\n",
    "\n",
    "#Since our model has a bunch of coffeicnets , we're going to use RFE in order to figure out which variables to elimate from our\n",
    "#model. once we near our list, then we will have completed building a logistic regression model!\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "#I picked 10 features as the number of features to select \n",
    "#Not sure if we need to make logisticregression equation = previous ones\n",
    " \n",
    "rfe = RFE(lr_clf, 10)\n",
    "\n",
    "\n",
    "rfe = rfe.fit(X_res, y_res.ravel())\n",
    "\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)\n",
    "#This gives us the column names from RFE feature selection.\n",
    "df_new.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  PAY_5  PAY_6\n",
       "0    2          2         1   24      2      2     -1     -1     -2     -2\n",
       "1    2          2         2   26     -1      2      0      0      0      2\n",
       "2    2          2         2   34      0      0      0      0      0      0\n",
       "3    2          2         1   37      0      0      0      0      0      0\n",
       "4    1          2         1   57     -1      0     -1      0      0      0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The above True/False line up with the columns\n",
    "#'SEX','EDUCATION','EDUCATION','AGE','PAY_0','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6','PAY_AMT1'\n",
    "#So we need to reorg the dataframe X_res then continue with the process\n",
    "\n",
    "X_rs = pd.DataFrame(data=X_res,columns=col)\n",
    "\n",
    "imp_col = ['SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3',\n",
    "          'PAY_4', 'PAY_5', 'PAY_6']\n",
    "\n",
    "X_rs  = X_rs[imp_col]\n",
    "\n",
    "y_rs = pd.DataFrame(data=y_res,columns=['default_payment_next_month'])\n",
    "\n",
    "#Checking the heads to make sure it worked\n",
    "X_rs.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.605215\n",
      "         Iterations 5\n",
      "                              Results: Logit\n",
      "===========================================================================\n",
      "Model:              Logit                      Pseudo R-squared: 0.127     \n",
      "Dependent Variable: default_payment_next_month AIC:              55690.1095\n",
      "Date:               2021-02-07 20:08           BIC:              55777.4717\n",
      "No. Observations:   45992                      Log-Likelihood:   -27835.   \n",
      "Df Model:           9                          LL-Null:          -31879.   \n",
      "Df Residuals:       45982                      LLR p-value:      0.0000    \n",
      "Converged:          1.0000                     Scale:            1.0000    \n",
      "No. Iterations:     5.0000                                                 \n",
      "------------------------------------------------------------------------------\n",
      "                Coef.     Std.Err.       z        P>|z|      [0.025     0.975]\n",
      "------------------------------------------------------------------------------\n",
      "SEX            -0.3014      0.0185    -16.3291    0.0000    -0.3375    -0.2652\n",
      "EDUCATION      -0.2358      0.0153    -15.3666    0.0000    -0.2659    -0.2057\n",
      "MARRIAGE       -0.3050      0.0164    -18.6083    0.0000    -0.3371    -0.2729\n",
      "AGE             0.0326      0.0009     36.5035    0.0000     0.0308     0.0343\n",
      "PAY_0           0.6041      0.0132     45.7076    0.0000     0.5782     0.6300\n",
      "PAY_2           0.1097      0.0149      7.3661    0.0000     0.0805     0.1389\n",
      "PAY_3           0.0774      0.0165      4.6953    0.0000     0.0451     0.1097\n",
      "PAY_4           0.0315      0.0183      1.7158    0.0862    -0.0045     0.0674\n",
      "PAY_5           0.0622      0.0198      3.1394    0.0017     0.0234     0.1010\n",
      "PAY_6          -0.0232      0.0162     -1.4321    0.1521    -0.0549     0.0085\n",
      "===========================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now we check the P-values of our model to futhur elimate variables!\n",
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(y_rs,X_rs)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45987</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45988</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45989</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45990</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45991</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45992 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SEX  EDUCATION  AGE  PAY_0  PAY_2  PAY_3  PAY_5\n",
       "0        2          2   24      2      2     -1     -2\n",
       "1        2          2   26     -1      2      0      0\n",
       "2        2          2   34      0      0      0      0\n",
       "3        2          2   37      0      0      0      0\n",
       "4        1          2   57     -1      0     -1      0\n",
       "...    ...        ...  ...    ...    ...    ...    ...\n",
       "45987    1          1   49     -1     -2     -2     -1\n",
       "45988    2          2   27      1      0      0      0\n",
       "45989    2          1   23      0      0      1      0\n",
       "45990    1          2   24     -1     -1     -1     -2\n",
       "45991    1          1   27      0      1      1      0\n",
       "\n",
       "[45992 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#So based on the output above, We are only removing PAY_6 since it isn't signficiant as per pvalue of .1521 &\n",
    "#PAY_4 0.0862 \n",
    "p_cols =  ['SEX','EDUCATION','AGE','PAY_0','PAY_2','PAY_3','PAY_5']\n",
    "\n",
    "X_cols = X_rs[p_cols]\n",
    "\n",
    "\n",
    "X_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "Accuracy 0.7\n",
      "sensitivity: 0.71\n",
      "specificity: 0.69\n",
      "====Iteration 1  ====\n",
      "Accuracy 0.69\n",
      "sensitivity: 0.7\n",
      "specificity: 0.68\n",
      "====Iteration 2  ====\n",
      "Accuracy 0.68\n",
      "sensitivity: 0.7\n",
      "specificity: 0.67\n",
      "====Iteration 3  ====\n",
      "Accuracy 0.68\n",
      "sensitivity: 0.69\n",
      "specificity: 0.67\n",
      "====Iteration 4  ====\n",
      "Accuracy 0.69\n",
      "sensitivity: 0.7\n",
      "specificity: 0.68\n",
      "====Iteration 5  ====\n",
      "Accuracy 0.69\n",
      "sensitivity: 0.71\n",
      "specificity: 0.68\n",
      "====Iteration 6  ====\n",
      "Accuracy 0.69\n",
      "sensitivity: 0.7\n",
      "specificity: 0.68\n",
      "====Iteration 7  ====\n",
      "Accuracy 0.68\n",
      "sensitivity: 0.7\n",
      "specificity: 0.67\n",
      "====Iteration 8  ====\n",
      "Accuracy 0.69\n",
      "sensitivity: 0.7\n",
      "specificity: 0.68\n",
      "====Iteration 9  ====\n",
      "Accuracy 0.69\n",
      "sensitivity: 0.7\n",
      "specificity: 0.68\n"
     ]
    }
   ],
   "source": [
    "#Now we are going to reuse the code from above and score our final logic regression model!\n",
    "\n",
    "\n",
    "X_res = X_cols.values\n",
    "\n",
    "\n",
    "#Setting up  the CV, code utlized from 04 Logits & SVM notebook\n",
    "num_cv_iterations = 10\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         random_state = seed,\n",
    "                         test_size  = 0.2)\n",
    "\n",
    "#code utlized from 04 Logits & SVM notebook\n",
    "std_scl = StandardScaler()\n",
    "lr_clf = LogisticRegression(penalty='l2', C=0.05, solver='liblinear') \n",
    "\n",
    "# create the pipline\n",
    "#code utlized from 04 Logits & SVM notebook\n",
    "piped_object = Pipeline([('scale', std_scl),  # do this\n",
    "                         ('logit_model', lr_clf)]) # and then do this\n",
    "\n",
    "\n",
    "\n",
    "weights_final = []\n",
    "for iter_num, (train_indices, test_indices) in enumerate(cv_object.split(X_res,y_res)):\n",
    "    piped_object.fit(X_res[train_indices],y_res[train_indices])  # train object\n",
    "    y_hat = piped_object.predict(X_res[test_indices])\n",
    "    weights_final.append(piped_object.named_steps['logit_model'].coef_[0])\n",
    "    \n",
    "    cm1 = mt.confusion_matrix(y_res[test_indices],y_hat)\n",
    "    \n",
    "    sensitivity1= cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    \n",
    "    specificity1= cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    \n",
    "    # print the accuracy and confusion matrix \n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"Accuracy\", round(mt.accuracy_score(y_res[test_indices],y_hat),2))\n",
    "   \n",
    "    \n",
    "    print('sensitivity:',round(sensitivity1,2))\n",
    "    print('specificity:',round(specificity1,2))\n",
    "\n",
    "weights_final = np.array(weights_final)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "SEX has weight of -0.3795\n",
      "EDUCATION has weight of -0.2841\n",
      "AGE has weight of 0.0664\n",
      "PAY_5 has weight of 0.0908\n",
      "PAY_3 has weight of 0.0963\n",
      "PAY_2 has weight of 0.1318\n",
      "PAY_0 has weight of 0.6629\n"
     ]
    }
   ],
   "source": [
    "#Weights of the final model, Again not sure if this code is correct or not.\n",
    "\n",
    "print('---------------------------------------------')\n",
    "zip_vars = zip(lr_clf.coef_.T,X_cols.columns) # combine attributes\n",
    "zip_vars = sorted(zip_vars)\n",
    "for coef, name in zip_vars:\n",
    "    print(name, 'has weight of', round(coef[0],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put interpation of weights\n",
    "\n",
    "#Need to finalize ROC curve for final logistric model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7175779976084357\n",
      "[[3511 1074]\n",
      " [1524 3090]]\n",
      "Wall time: 36.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##Just to get an idea, this can be deleted later.\n",
    "scl_obj = StandardScaler()\n",
    "\n",
    "# okay, so run through the cross validation loop and set the training and testing variable for one single iteration\n",
    "for train_indices, test_indices in cv_object.split(X_res,y_res): \n",
    "    # I will create new variables here so that it is more obvious what \n",
    "    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "    # but it makes this code less readable)\n",
    "    X_train = X_res[train_indices]\n",
    "    y_train = y_res[train_indices]\n",
    "    \n",
    "    X_test = X_res[test_indices]\n",
    "    y_test = y_res[test_indices]\n",
    "    \n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# train the model just as before\n",
    "svm_clf = SVC(C=0.5, kernel='rbf', degree=3, gamma='auto') # get object\n",
    "svm_clf.fit(X_train, y_train)  # train object\n",
    "\n",
    "y_hat = svm_clf.predict(X_test) # get test set precitions\n",
    "\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "print('accuracy:', acc )\n",
    "print(conf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#followed example from Unit 4 workbook\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Support vector\n",
    "svm_clf = SVC(C=0.5, kernel='rbf', degree=3, gamma='auto')\n",
    "\n",
    "piped_object_svm = Pipeline([('scale', std_scl),  # do this\n",
    "                         ('logit_model', svm_clf)]) # and then do this\n",
    "\n",
    "\n",
    "for iter_num, (train_indices, test_indices) in enumerate(cv_object.split(X_res,y_res)):\n",
    "    piped_object_svm.fit(X_res[train_indices],y_res[train_indices])  \n",
    "    y_hat = piped_object_svm.predict(X_res[test_indices])\n",
    "    \n",
    "    cm1 = mt.confusion_matrix(y_res[test_indices],y_hat)\n",
    "    \n",
    "    sensitivity1= cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    \n",
    "    specificity1= cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    \n",
    "    # print the accuracy and confusion matrix \n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"Accuracy\", round(mt.accuracy_score(y_res[test_indices],y_hat),2))\n",
    "   \n",
    "    \n",
    "    print('sensitivity:',round(sensitivity1,2))\n",
    "    print('specificity:',round(specificity1,2))\n",
    "                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so we need to do a stochastic descent to reduce run time, as 10 mins to do above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        SVC(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "\n",
    "    piped_object_svm = Pipeline([('scale', std_scl),  \n",
    "                         ('logit_model', clf)])\n",
    "\n",
    "  \n",
    "\n",
    "    piped_object_svm.fit(X_res, y_res)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "regularize_const = 0.1\n",
    "iterations = 5\n",
    "\n",
    "svm_sgd = SGDClassifier(alpha=regularize_const,\n",
    "        fit_intercept=True, l1_ratio=0.0, learning_rate='optimal',\n",
    "        loss='hinge', n_iter_no_change=iterations, n_jobs=-1, penalty='l2')\n",
    "\n",
    "piped_object_svm = Pipeline([('scale', std_scl),  \n",
    "                         ('svm', svm_sgd)])\n",
    "\n",
    "\n",
    "for iter_num, (train_indices, test_indices) in enumerate(cv_object.split(X_res,y_res)):\n",
    "    piped_object_svm.fit(X_res[train_indices],y_res[train_indices])  \n",
    "    y_hat = piped_object_svm.predict(X_res[test_indices])\n",
    "\n",
    "    cm1 = mt.confusion_matrix(y_res[test_indices],y_hat)\n",
    "    \n",
    "    sensitivity1= cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    \n",
    "    specificity1= cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    \n",
    "    # print the accuracy and confusion matrix \n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"Accuracy\", round(mt.accuracy_score(y_res[test_indices],y_hat),2))\n",
    "   \n",
    "    \n",
    "    print('sensitivity:',round(sensitivity1,2))\n",
    "    print('specificity:',round(specificity1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=  45.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=  46.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=  45.8s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=  44.9s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=  46.2s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=  29.7s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=  29.5s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=  29.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=  29.3s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=  29.7s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=  38.8s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=  38.3s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=  38.8s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=  37.9s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=  39.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=  42.2s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=  42.7s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=  42.8s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=  42.8s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=  42.7s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=  29.2s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=  29.1s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=  29.2s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=  29.5s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=  29.7s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=  36.9s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=  36.6s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=  37.0s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=  37.5s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=  36.2s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=  40.6s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=  41.3s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=  40.3s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=  40.6s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=  40.6s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=  27.3s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=  27.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=  26.9s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=  28.3s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=  26.9s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=  31.7s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=  31.9s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=  28.8s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=  31.3s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=  28.1s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=  43.4s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=  43.3s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=  43.8s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=  42.9s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=  42.6s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=10.4min\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=13.3min\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time= 9.1min\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=12.0min\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time= 7.7min\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=  33.9s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=  33.6s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=  33.8s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=  34.2s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=  35.9s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=  42.9s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=  44.4s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=  42.5s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=  42.8s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=  45.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=  30.6s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=  30.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=  30.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=  29.7s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=  30.0s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=  36.1s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=  35.7s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=  35.9s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=  36.2s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=  35.8s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=  41.8s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=  42.3s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=  42.9s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=  42.7s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=  42.1s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=  28.7s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=  28.3s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=  29.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=  28.6s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=  28.4s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=  33.2s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=  34.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=  35.0s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=  33.8s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=  34.2s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=  41.2s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=  41.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=  41.1s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=  40.4s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=  40.4s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=  32.6s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=  38.8s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=  33.2s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=  35.1s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=  31.7s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=  29.2s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=  30.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=  26.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=  28.3s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=  25.4s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time= 1.0min\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time= 1.0min\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=  59.5s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=  59.7s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time= 1.0min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size = 0.20)\n",
    "\n",
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [.001,.01,.1,1],'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "\n",
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\n",
    "piped_object_grid = Pipeline([('scale', std_scl),  \n",
    "                         ('svm', grid)])\n",
    "\n",
    "\n",
    "piped_object_grid.fit(X_train,y_train)\n",
    "\n",
    "print(piped_object_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
